name: Reusable build frontend code and send it to a specified AWS EC2 instance

on:
  workflow_call:
    inputs:
      repo-name:
        description: 'name of repository'
        required: true
        type: string
      node-version:
        description: 'Node version'
        required: true
        type: string
      build-command:
        description: 'Build command'
        required: true
        type: string
      s3-aws-region:
        description: 'AWS Region for S3 Bucket'
        required: true
        type: string
      isMainnet:
        description: 'Whether we are deploying to mainnet'
        required: true
        type: boolean
    secrets:
      S3_OWNER_ACCESS_KEY_ID:
        description: 'AWS S3 Owner Access Key ID'
        required: true
      S3_OWNER_SECRET_ACCESS_KEY:
        description: 'AWS S3 Owner Secret Access Key'
        required: true
      EC2_SSH_KEY:
        description: 'Name of the EC2 SSH Key'
        required: true
      EC2_USER:
        description: 'User for EC2 Instance'
        required: true
      EC2_HOST:
        description: 'Hostname of the EC2 Instance'
        required: true
      CLOUDFLARE_API_TOKEN:
        description: 'Cloudflare API Token'
        required: true
      CLOUDFLARE_ZONE_ID:
        description: 'Cloudflare Zone ID'
        required: true

env:
  # AWS Configuration
  AWS_ROLE_ARN: "arn:aws:iam::471112752664:role/GitHubAction-AssumeRoleWithAction"
  AWS_REGION: "us-west-1"
  AWS_DEFAULT_DEPLOYMENT_PATH: /data/treasurenet
  MAINNET_AWS_DEFAULT_DEPLOYMENT_PATH: /home/ubuntu/treasurenet
  BUCKET_NAME: tn-deployment-file-archive
  MAINNET_BUCKET_NAME: tn-mainnet-deployment-file-archive
  SERVICE_NAME: services
  aws-region: us-west-1
  EC2_USER: ${{secrets.EC2_USER}}
  EC2_HOST: ${{secrets.EC2_HOST}}
  NGINX_PATH: /data/nginx
  MAINNET_NGINX_PATH: /home/ubuntu/nginx
  aws-dev-secret-name: dev/services
  aws-testnet-secret-name: testnet/services
  aws-mainnet-secret-name: mainnet/services

jobs:
  build:
    runs-on: self-hosted

    steps:
      - name: Set date and time
        run: |
          echo "DATE=$(date '+%Y%m%d')"  >> $GITHUB_ENV
          echo "TIME=$(date '+%Y%m%d_%H%M%S')" >> $GITHUB_ENV

      - name: Checkout code
        uses: actions/checkout@0ad4b8fadaa221de15dcec353f45205ec38ea70b # v4.1.4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ inputs.node-version }}


      - name: Get EC2 details from AWS
        if: ${{ !env.EC2_HOST && !inputs.isMainnet}}  
        run: |
          public_ip=$(aws ec2 describe-instances \
            --region ${{ env.aws-region }} \
            --filters "Name=tag:Name,Values=${{ env.SERVICE_NAME }}" "Name=instance-state-name,Values=running" \
            --query "Reservations[*].Instances[*].PublicIpAddress" \
            --output text)
          
          echo "EC2_HOST=$public_ip" >> $GITHUB_ENV
          echo "EC2_USER=ubuntu" >> $GITHUB_ENV  

      - name: Configure AWS credentials
        if: ${{ !env.EC2_HOST && inputs.isMainnet}}  
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ env.AWS_ROLE_ARN }}
          role-session-name: GitHub_to_AWS_via_FederatedOIDC
          aws-region: ${{ env.AWS_REGION }}

      - name: Get EC2 details from AWS
        if: ${{ !env.EC2_HOST && inputs.isMainnet}}  
        run: |
          public_dns=$(aws ec2 describe-instances \
            --region ${{ env.aws-region }} \
            --filters "Name=tag:Name,Values=web-service-1-us-west-1" \
                      "Name=instance-state-name,Values=running" \
            --query "Reservations[].Instances[].PublicDnsName" \
            --output text)
          echo "EC2_HOST=$public_dns" >> $GITHUB_ENV
          echo "EC2_USER=ubuntu" >> $GITHUB_ENV  
            
      - name: Build code
        run: |
          npm install --silent
          npm run ${{ inputs.build-command }} --slient

      - name: Archive files
        run: |
          tar -zcvf ./${{ inputs.repo-name }}.tar.gz -C dist . 
          tar -zcvf ./${{ inputs.repo-name }}_nginx.tar.gz -C nginx .


      - name: Upload Archive file to AWS S3
        shell: bash
        run: |
          if [ "${{ inputs.isMainnet }}" != "true" ]; then
            aws configure set aws_access_key_id     ${{ secrets.S3_OWNER_ACCESS_KEY_ID }}
            aws configure set aws_secret_access_key ${{ secrets.S3_OWNER_SECRET_ACCESS_KEY }}
            aws configure set region                ${{ inputs.s3-aws-region }}
            BUCKET=${{ env.BUCKET_NAME }}
          else
            BUCKET=${{ env.MAINNET_BUCKET_NAME }}
          fi

          aws s3 cp ./${{ inputs.repo-name }}.tar.gz \
            s3://$BUCKET/${{ inputs.repo-name }}/${{ env.DATE }}/${{ inputs.repo-name }}_${{ env.TIME }}.tar.gz

          aws s3 cp ./${{ inputs.repo-name }}_nginx.tar.gz \
            s3://$BUCKET/${{ inputs.repo-name }}/${{ env.DATE }}/${{ inputs.repo-name }}_nginx_${{ env.TIME }}.tar.gz

      - name: Set up ssh key
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.EC2_SSH_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa  

      - name: Download(from AWS S3), extract and replace files
        if: ${{ !inputs.isMainnet}}  
        run: |
          ssh -o StrictHostKeyChecking=no ${{ env.EC2_USER }}@${{ env.EC2_HOST }} << EOF
          
            aws configure set aws_access_key_id ${{ secrets.S3_OWNER_ACCESS_KEY_ID }}
            aws configure set aws_secret_access_key ${{ secrets.S3_OWNER_SECRET_ACCESS_KEY }}
            aws configure set region ${{ inputs.s3-aws-region }}
            aws s3 cp s3://${{ env.BUCKET_NAME }}/${{ inputs.repo-name }}/${{ env.DATE }}/${{ inputs.repo-name }}_${{ env.TIME }}.tar.gz /home/${{ env.EC2_USER }}/${{ inputs.repo-name }}.tar.gz
            aws s3 cp s3://${{ env.BUCKET_NAME }}/${{ inputs.repo-name }}/${{ env.DATE }}/${{ inputs.repo-name }}_nginx_${{ env.TIME }}.tar.gz /home/${{ env.EC2_USER }}/${{ inputs.repo-name }}_nginx.tar.gz
          
            mkdir -p ${{ env.AWS_DEFAULT_DEPLOYMENT_PATH }}/${{ inputs.repo-name }}
            rm -rf ${{ env.AWS_DEFAULT_DEPLOYMENT_PATH }}/${{ inputs.repo-name }}/*
            tar -zxvf /home/${{ env.EC2_USER }}/${{ inputs.repo-name }}.tar.gz -C ${{ env.AWS_DEFAULT_DEPLOYMENT_PATH }}/${{ inputs.repo-name }}
            rm -rf /home/${{ env.EC2_USER }}/${{ inputs.repo-name }}.tar.gz

            mkdir -p ${{ env.NGINX_PATH }}
            tar -zxvf /home/${{ env.EC2_USER }}/${{ inputs.repo-name }}_nginx.tar.gz -C ${{ env.NGINX_PATH }}
            rm -rf /home/${{ env.EC2_USER }}/${{ inputs.repo-name }}_nginx.tar.gz
          
          EOF

      - name: Download(from AWS S3), extract and replace files
        if: ${{ inputs.isMainnet}}  
        run: |
          ssh -o StrictHostKeyChecking=no ${{ env.EC2_USER }}@${{ env.EC2_HOST }} << EOF
           aws s3api get-object \
            --bucket ${{ env.MAINNET_BUCKET_NAME }} \
            --key ${{ inputs.repo-name }}/${{ env.DATE }}/${{ inputs.repo-name }}_${{ env.TIME }}.tar.gz \
            /home/${{ env.EC2_USER }}/${{ inputs.repo-name }}.tar.gz

            aws s3api get-object \
            --bucket ${{ env.MAINNET_BUCKET_NAME }} \
            --key ${{ inputs.repo-name }}/${{ env.DATE }}/${{ inputs.repo-name }}_nginx_${{ env.TIME }}.tar.gz \
            /home/${{ env.EC2_USER }}/${{ inputs.repo-name }}_nginx.tar.gz

            mkdir -p ${{ env.MAINNET_AWS_DEFAULT_DEPLOYMENT_PATH }}/${{ inputs.repo-name }}
            rm -rf ${{ env.MAINNET_AWS_DEFAULT_DEPLOYMENT_PATH }}/${{ inputs.repo-name }}/*
            tar -zxvf /home/${{ env.EC2_USER }}/${{ inputs.repo-name }}.tar.gz -C ${{ env.MAINNET_AWS_DEFAULT_DEPLOYMENT_PATH }}/${{ inputs.repo-name }}
            rm -rf /home/${{ env.EC2_USER }}/${{ inputs.repo-name }}.tar.gz

            mkdir -p ${{ env.MAINNET_NGINX_PATH }}
            tar -zxvf /home/${{ env.EC2_USER }}/${{ inputs.repo-name }}_nginx.tar.gz -C ${{ env.MAINNET_NGINX_PATH }}
            rm -rf /home/${{ env.EC2_USER }}/${{ inputs.repo-name }}_nginx.tar.gz
          
          EOF


      - name: add nginx cloudflare
        if: ${{ !inputs.isMainnet }}
        run: |
           ssh -o StrictHostKeyChecking=no ${{ env.EC2_USER }}@${{ env.EC2_HOST }} <<EOF
            aws configure set aws_access_key_id ${{ secrets.S3_OWNER_ACCESS_KEY_ID }}
            aws configure set aws_secret_access_key ${{ secrets.S3_OWNER_SECRET_ACCESS_KEY }}
            aws configure set region ${{ inputs.s3-aws-region }}
            mkdir -p ${{ env.NGINX_PATH }}/certs
            if [ -z "${{ env.EC2_HOST }}" ]; then
            
              SECRET_ID="${{ env.aws-dev-secret-name }}/nginx"
            else
            
              SECRET_ID="${{ env.aws-testnet-secret-name }}/nginx"
            fi
            SECRET_STRING=\$(aws secretsmanager get-secret-value --secret-id \$SECRET_ID --region ${{ env.aws-region }} --query SecretString --output text)
            echo "\$SECRET_STRING" | jq -r .ssl_certificate > ${{ env.NGINX_PATH }}/certs/cloudflare.pem
            echo "\$SECRET_STRING" | jq -r .ssl_key > ${{ env.NGINX_PATH }}/certs/cloudflare.key

           EOF

      - name: add nginx cloudflare
        if: ${{ inputs.isMainnet }}
        run: |
           ssh -o StrictHostKeyChecking=no ${{ env.EC2_USER }}@${{ env.EC2_HOST }} <<EOF
           
           
              SECRET_ID="${{ env.aws-mainnet-secret-name }}/nginx"
            SECRET_STRING=\$(aws secretsmanager get-secret-value --secret-id \$SECRET_ID --region ${{ env.aws-region }} --query SecretString --output text)
            echo "\$SECRET_STRING" | jq -r .ssl_certificate > ${{ env.MAINNET_NGINX_PATH }}/certs/cloudflare.pem
            echo "\$SECRET_STRING" | jq -r .ssl_key > ${{ env.MAINNET_NGINX_PATH }}/certs/cloudflare.key

           EOF

      - name: up nginx docker
        if: ${{ !inputs.isMainnet }}
        run: |
          ssh -o StrictHostKeyChecking=no ${{ env.EC2_USER }}@${{ env.EC2_HOST }} << EOF
          aws configure set aws_access_key_id ${{ secrets.S3_OWNER_ACCESS_KEY_ID }}
            aws configure set aws_secret_access_key ${{ secrets.S3_OWNER_SECRET_ACCESS_KEY }}
            aws configure set region ${{ inputs.s3-aws-region }}
            cd ${{ env.NGINX_PATH }}
             if docker-compose ps | grep -q "Up"; then
              echo "Docker Compose is running."
              docker-compose restart
            else
              echo "Docker Compose is not running."
              docker-compose up -d
            fi
          EOF

      - name: up nginx docker
        if: ${{ inputs.isMainnet }}
        run: |
          ssh -o StrictHostKeyChecking=no ${{ env.EC2_USER }}@${{ env.EC2_HOST }} << EOF
         
            cd ${{ env.MAINNET_NGINX_PATH }}
             if docker-compose ps | grep -q "Up"; then
              echo "Docker Compose is running."
              docker-compose restart
            else
              echo "Docker Compose is not running."
              docker-compose up -d
            fi
          EOF


      - name: Purge cloudflare cache
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ZONE_ID: ${{ secrets.CLOUDFLARE_ZONE_ID }}
        run: |
          curl -X POST "https://api.cloudflare.com/client/v4/zones/${CLOUDFLARE_ZONE_ID}/purge_cache" \
          -H "Authorization: Bearer ${CLOUDFLARE_API_TOKEN}" \
          -H "Content-Type: application/json" \
          --data '{"purge_everything":true}'    
